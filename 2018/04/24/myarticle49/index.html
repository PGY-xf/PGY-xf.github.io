<!DOCTYPE html>

<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
  <title>大数据概念 [ Pandsflies ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/iLiKE.css">
    
  
  
  
  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
    <script id="leancloud">
      AV.init({
          appId: "6E5zTbTljdUbVW2WkXPsXGJk-gzGzoHsz",
          appKey: "0vsyDKfNpeSECAI70J794ugv"
      });
    </script>

</head></html>
<body>
    <div class="header">
        <div class="container">
    <div class="menu">
      <div class="menu-left">
        <a href="/">
          <img src="/favicon.ico"></img>
        </a>
      </div>
      <div class="menu-right">
        
          
          
          
          
          
          
          <a href="/">Home</a>
        
          
          
          
          
          
          
          <a href="/archives">Archives</a>
        
          
          
          
          
          
          <a href="/about">Resume</a>
        
          
          
          
          
          
          <a href="/E-BOOK">E-book</a>
        
      </div>
    </div>
</div>
    </div>
    <div class="container">
        <h1 class="post-title">大数据概念</h1>
<article class="post markdown-style">
  <h1 id="1、什么是大数据"><a href="#1、什么是大数据" class="headerlink" title="1、什么是大数据"></a>1、什么是大数据</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>《数据处理》</p>
<p>在互联网技术发展到现今阶段，大量日常、工作等事务产生的数据都已经信息化，人类产生的数据量相比以前有了爆炸式的增长，以前的传统的数据处理技术已经无法胜任，需求催生技术，一套用来处理海量数据的软件工具应运而生，这就是大数据！</p>
<p>处理海量数据的核心技术：</p>
<p>海量数据存储：分布式</p>
<p>海量数据运算：分布式</p>
<p>这些核心技术的实现是不需要用户从零开始造轮子的</p>
<p>存储和运算，都已经有大量的成熟的框架来用</p>
<p>存储框架：</p>
<p>HDFS——分布式文件存储系统（HADOOP中的存储框架）</p>
<p>HBASE——分布式数据库系统</p>
<p>KAFKA——分布式消息缓存系统(实时流式数据处理场景中应用广泛)</p>
<p>运算框架：（要解决的核心问题就是帮用户将处理逻辑在很多机器上并行）</p>
<p>MAPREDUCE—— 离线批处理/HADOOP中的运算框架</p>
<p>SPARK —— 离线批处理/实时流式计算</p>
<p>STORM —— 实时流式计算</p>
<p>辅助类的工具（解放大数据工程师的一些繁琐工作）：</p>
<p>​    HIVE —— 数据仓库工具：可以接收sql，翻译成mapreduce或者spark程序运行</p>
<p>FLUME——数据采集</p>
<p>SQOOP——数据迁移</p>
<p>ELASTIC SEARCH —— 分布式的搜索引擎</p>
<p>…….</p>
<p>换个角度说，大数据是：</p>
<p>1、有海量的数据</p>
<p>2、有对海量数据进行挖掘的需求</p>
<p>3、有对海量数据进行挖掘的软件工具（hadoop、spark、storm、flink、tez、impala……）</p>
<h2 id="大数据在现实生活中的具体应用"><a href="#大数据在现实生活中的具体应用" class="headerlink" title="大数据在现实生活中的具体应用"></a>大数据在现实生活中的具体应用</h2><p>数据处理的最典型应用：公司的产品运营情况分析</p>
<p>电商推荐系统：基于海量的浏览行为、购物行为数据，进行大量的算法模型的运算，得出各类推荐结论，以供电商网站页面来为用户进行商品推荐</p>
<p>精准广告推送系统：基于海量的互联网用户的各类数据，统计分析，进行用户画像（得到用户的各种属性标签），然后可以为广告主进行有针对性的精准的广告投放</p>
<h1 id="2、什么是hadoop"><a href="#2、什么是hadoop" class="headerlink" title="2、什么是hadoop"></a>2、什么是hadoop</h1><p>hadoop中有3个核心组件：</p>
<p>分布式文件系统：HDFS —— 实现将文件分布式存储在很多的服务器上</p>
<p>分布式运算编程框架：MAPREDUCE —— 实现在很多机器上分布式并行运算</p>
<p>分布式资源调度平台：YARN —— 帮用户调度大量的mapreduce程序，并合理分配运算资源</p>
<h1 id="3、hdfs整体运行机制"><a href="#3、hdfs整体运行机制" class="headerlink" title="3、hdfs整体运行机制"></a>3、hdfs整体运行机制</h1><p>hdfs：分布式文件系统</p>
<p>hdfs有着文件系统共同的特征：</p>
<p>1、有目录结构，顶层目录是：  /</p>
<p>2、系统中存放的就是文件</p>
<p>3、系统可以提供对文件的：创建、删除、修改、查看、移动等功能</p>
<p>hdfs跟普通的单机文件系统有区别：</p>
<p>1、单机文件系统中存放的文件，是在一台机器的操作系统中</p>
<p>2、hdfs的文件系统会横跨N多的机器</p>
<p>3、单机文件系统中存放的文件，是在一台机器的磁盘上</p>
<p>4、hdfs文件系统中存放的文件，是落在n多机器的本地单机文件系统中（hdfs是一个基于linux本地文件系统之上的文件系统）</p>
<p>hdfs的工作机制：</p>
<p>1、客户把一个文件存入hdfs，其实hdfs会把这个文件切块后，分散存储在N台linux机器系统中（负责存储文件块的角色：data node）&lt;准确来说：切块的行为是由客户端决定的&gt;</p>
<p>2、一旦文件被切块存储，那么，hdfs中就必须有一个机制，来记录用户的每一个文件的切块信息，及每一块的具体存储机器（负责记录块信息的角色是：name node）</p>
<p>3、为了保证数据的安全性，hdfs可以将每一个文件块在集群中存放多个副本（到底存几个副本，是由当时存入该文件的客户端指定的）</p>
<p>综述：一个hdfs系统，由一台运行了namenode的服务器，和N台运行了datanode的服务器组成！</p>
<h1 id="4、搭建hdfs分布式集群"><a href="#4、搭建hdfs分布式集群" class="headerlink" title="4、搭建hdfs分布式集群"></a>4、搭建hdfs分布式集群</h1><h3 id="4-1-hdfs集群组成结构："><a href="#4-1-hdfs集群组成结构：" class="headerlink" title="4.1 hdfs集群组成结构："></a>4.1 hdfs集群组成结构：</h3><h3 id="4-2-安装hdfs集群的具体步骤："><a href="#4-2-安装hdfs集群的具体步骤：" class="headerlink" title="4.2 安装hdfs集群的具体步骤："></a>4.2 安装hdfs集群的具体步骤：</h3><p><strong>一、首先需要准备N**</strong>台linux<strong>**服务器</strong></p>
<p>学习阶段，用虚拟机即可！</p>
<p>先准备4台虚拟机：1个namenode节点  + 3 个datanode 节点</p>
<p><strong>二、修改各台机器的主机名和ip**</strong>地址**</p>
<p>主机名：hdp-01  对应的ip地址：192.168.33.61</p>
<p>主机名：hdp-02  对应的ip地址：192.168.33.62</p>
<p>主机名：hdp-03  对应的ip地址：192.168.33.63</p>
<p>主机名：hdp-04  对应的ip地址：192.168.33.64</p>
<p>三、从windows中用CRT软件进行远程连接</p>
<p>在windows中将各台linux机器的主机名配置到的windows的本地域名映射文件中：</p>
<p>c:/windows/system32/drivers/etc/hosts</p>
<p>用crt连接上后，修改一下crt的显示配置（字号，编码集改为UTF-8）：</p>
<p><strong>四、配置linux**</strong>服务器的基础软件环境**</p>
<p>l  防火墙</p>
<p>关闭防火墙：service iptables stop </p>
<p>关闭防火墙自启： chkconfig iptables off</p>
<p>l  安装jdk：（hadoop体系中的各软件都是java开发的）</p>
<p>1)         利用alt+p 打开sftp窗口，然后将jdk压缩包拖入sftp窗口</p>
<p>2)         然后在linux中将jdk压缩包解压到/root/apps 下</p>
<p>3)         配置环境变量：JAVA_HOME   PATH</p>
<p>vi /etc/profile   在文件的最后，加入：</p>
<p>4)         修改完成后，记得 source /etc/profile使配置生效</p>
<p>5)         检验：在任意目录下输入命令： java -version 看是否成功执行</p>
<p>6)         将安装好的jdk目录用scp命令拷贝到其他机器</p>
<p>7)         将/etc/profile配置文件也用scp命令拷贝到其他机器并分别执行source命令</p>
<p>l  集群内主机的<strong>域名映射</strong>配置</p>
<p>在hdp-01上，vi /etc/hosts</p>
<p>然后，将hosts文件拷贝到集群中的所有其他机器上</p>
<p>scp /etc/hosts hdp-02:/etc/</p>
<p>scp /etc/hosts hdp-03:/etc/</p>
<p>scp /etc/hosts hdp-04:/etc/</p>
<table>
<thead>
<tr>
<th>补充提示:</th>
<th>如果在执行scp命令的时候，提示没有scp命令，则可以配置一个本地yum源来安装1、先在虚拟机中配置cdrom为一个centos的安装镜像iso文件2、在linux系统中将光驱挂在到文件系统中（某个目录）3、mkdir /mnt/cdrom4、mount -t iso9660 -o loop /dev/cdrom /mnt/cdrom5、检验挂载是否成功： ls /mnt/cdrom6、3、配置yum的仓库地址配置文件7、yum的仓库地址配置文件目录： /etc/yum.repos.d8、先将自带的仓库地址配置文件批量更名：  9、然后，拷贝一个出来进行修改  10、修改完配置文件后，再安装scp命令：11、yum install openssh-clients -y</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>l  <strong>五、安装hdfs**</strong>集群**</p>
<p>1、上传hadoop安装包到hdp-01</p>
<p>2、修改配置文件</p>
<table>
<thead>
<tr>
<th>要点提示</th>
<th><strong>核心配置参数：*</strong>1)*         <em>指定hadoop<strong>的默认文件系统为：hdfs</strong>2)</em>         <em>指定hdfs<strong>的namenode</strong>节点为哪台机器**3)</em>         <em>指定namenode*</em>软件存储元数据的*<em>本地目录**</em>4)         <em>指定datanode*</em>软件<strong>存放文件块的\</strong>本地目录***</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>hadoop的配置文件在：/root/apps/hadoop安装目录/etc/hadoop/</p>
<p><strong>1)</strong> <strong>修改hadoop-env.sh</strong></p>
<p><em>export JAVA_HOME=/root/apps/jdk1.8.0_60</em></p>
<p><strong>2)</strong> <strong>修改core-site.xml</strong></p>
<p><strong>3)</strong> <strong>修改hdfs-site.xml</strong></p>
<p><strong>4)</strong> <strong>拷贝整个hadoop**</strong>安装目录到其他机器**</p>
<p><em>scp -r /root/apps/hadoop-2.8.1  hdp-02:/root/apps/</em></p>
<p><em>scp -r /root/apps/hadoop-2.8.1  hdp-03:/root/apps/</em></p>
<p><em>scp -r /root/apps/hadoop-2.8.1  hdp-04:/root/apps/</em></p>
<p><strong>5)</strong> <strong>启动HDFS</strong></p>
<p>所谓的启动HDFS，就是在对的机器上启动对的软件</p>
<table>
<thead>
<tr>
<th>要点提示：</th>
<th><em>要运行hadoop<strong>的命令，需要在linux</strong>环境中配置HADOOP_HOME<strong>和PATH</strong>环境变量<strong>vi /etc/profile</strong>export JAVA_HOME=/root/apps/jdk1.8.0_60<strong>export HADOOP_HOME=/root/apps/hadoop-2.8.1</strong>export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</em></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><strong>首先，初始化namenode**</strong>的元数据目录**</p>
<p>要在hdp-01上执行hadoop的一个命令来初始化namenode的元数据存储目录</p>
<p><em>hadoop namenode -format</em></p>
<p>l  创建一个全新的元数据存储目录</p>
<p>l  生成记录元数据的文件fsimage</p>
<p>l  生成集群的相关标识：如：集群id——clusterID</p>
<p><strong>然后，启动namenode**</strong>进程（在hdp-01<strong>**上）</strong></p>
<p><em>hadoop-daemon.sh start namenode</em></p>
<p>启动完后，首先用jps查看一下namenode的进程是否存在</p>
<p><strong>然后，在windows**</strong>中用浏览器访问namenode<strong><strong>提供的web</strong></strong>端口：50070**</p>
<p><a href="http://hdp-01:50070" target="_blank" rel="noopener">http://hdp-01:50070</a></p>
<p><strong>然后，启动众datanode**</strong>们（在任意地方）**</p>
<p><em>hadoop-daemon.sh start datanode</em></p>
<p><strong>6)</strong> <strong>用自动批量启动脚本来启动HDFS</strong></p>
<p>1)         先配置hdp-01到集群中所有机器（包含自己）的免密登陆</p>
<p><em>2)</em>         配完免密后，可以执行一次  <em>ssh 0.0.0.0</em></p>
<p>3)         修改hadoop安装目录中/etc/hadoop/slaves（把需要启动datanode进程的节点列入）</p>
<p>4)         在hdp-01上用脚本：<strong>start-dfs.sh</strong> 来自动启动整个集群</p>
<p><strong>5)</strong>         如果要停止，则用脚本：<strong>stop-dfs.sh</strong></p>
<h1 id="5、hdfs的客户端操作"><a href="#5、hdfs的客户端操作" class="headerlink" title="5、hdfs的客户端操作"></a>5、hdfs的客户端操作</h1><h2 id="客户端的理解"><a href="#客户端的理解" class="headerlink" title="客户端的理解"></a>客户端的理解</h2><p>hdfs的客户端有多种形式：</p>
<p>1、网页形式</p>
<p>2、命令行形式</p>
<p>3、客户端在哪里运行，没有约束，只要运行客户端的机器能够跟hdfs集群联网</p>
<p>文件的切块大小和存储的副本数量，都是由客户端决定！</p>
<p>所谓的由客户端决定，是通过配置参数来定的</p>
<p>hdfs的客户端会读以下两个参数，来决定切块大小、副本数量：</p>
<p>切块大小的参数： dfs.blocksize</p>
<p>副本数量的参数： dfs.replication</p>
<p>上面两个参数应该配置在客户端机器的hadoop目录中的hdfs-site.xml中配置</p>
<h2 id="hdfs客户端的常用操作命令"><a href="#hdfs客户端的常用操作命令" class="headerlink" title="hdfs客户端的常用操作命令"></a>hdfs客户端的常用操作命令</h2><p>1、上传文件到hdfs中</p>
<p>hadoop fs -put /本地文件  /aaa</p>
<p>2、下载文件到客户端本地磁盘</p>
<p>hadoop fs -get /hdfs中的路径   /本地磁盘目录</p>
<p>3、在hdfs中创建文件夹</p>
<p>hadoop fs -mkdir  -p /aaa/xxx</p>
<p>4、移动hdfs中的文件（更名）</p>
<p>hadoop fs -mv /hdfs的路径1  /hdfs的另一个路径2</p>
<p>复制hdfs中的文件到hdfs的另一个目录</p>
<p>hadoop fs -cp /hdfs路径_1  /hdfs路径_2</p>
<p>5、删除hdfs中的文件或文件夹</p>
<p>hadoop fs -rm -r /aaa</p>
<p>6、查看hdfs中的文本文件内容</p>
<p>hadoop fs -cat /demo.txt</p>
<p>hadoop fs -tail -f /demo.txt</p>

</article>

    <div class="pagenator post-pagenator">
    
    
        <a class="extend prev post-prev" href="/2018/05/04/myarticle50/">prev</a>
    

    
    <p>last update time 2019-09-05</p>
    
    
        <a class="extend next post-next" href="/2018/04/12/myarticle48/">next</a>
    
    </div>

    </div>
    <div class="footer">
        <div class="container">
    <div class="social">
	<ul class="social-list">
		
			
				
				
				<li>
					<a href="mailto:1178752402@qq.com" title="email" target="_blank">
					<i class="fa fa-email"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://github.com/CaiChenghan" title="github" target="_self">
					<i class="fa fa-github"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://www.jianshu.com/u/565c8e790605" title="jianshu" target="_self">
					<i class="fa fa-jianshu"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
	</ul>
</div>
    <div class="copyright">
        <span>
            
            
            
                © 小飞 2017 - 2019
            
        </span>
    </div>
    <div class="power">
        <span>
            Powered by <a href="https://hexo.io">Hexo</a> & <a href="https://github.com/CaiChenghan/iLiKE">iLiKE Theme</a>
        </span>
    </div>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
    <!--page counter part-->
<script>
function addCount (Counter) {
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query = new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find({
        success: function(results) {
            if (results.length>0) {
                var counter=results[0];
                counter.fetchWhenSave(true); //get recent result
                counter.increment("time");
                counter.save();
            } else {
                var newcounter=new Counter();
                newcounter.set("title",title);
                newcounter.set("url",url);
                newcounter.set("time",1);
                newcounter.save(null,{
                    success: function(newcounter) {
                        //alert('New object created');
                    }, error: function(newcounter,error) {
                        alert('Failed to create');
                    }
                })
            }
        },
        error: function(error) {
            //find null is not a error
            alert('Error:'+error.code+" "+error.message);
        }
    });
}
$(function() {
    var Counter=AV.Object.extend("Counter");
    //only increse visit counting when intering a page
    if ($('.article-title').length == 1) {
       addCount(Counter);
    }
    var query=new AV.Query(Counter);
    query.descending("time");
    // the sum of popular posts
    query.limit(10); 
    query.find({
        success: function(results) {
                for(var i=0;i<results.length;i++) {
                    var counter=results[i];
                    title=counter.get("title");
                    url=counter.get("url");
                    time=counter.get("time");
                    // add to the popularlist widget
                    showcontent=title+" ("+time+")";
                    //notice the "" in href
                    $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                }
            },
        error: function(error) {
            alert("Error:"+error.code+" "+error.message);
        }
    });
});
</script>
</div>
    </div>
</body>
</html>
